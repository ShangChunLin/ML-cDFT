{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning for free energy functional for 1D Lennard Jones fluid\n",
    "## -Traning part\n",
    "***\n",
    "## -square+Cubic term\n",
    "## This takes quite long, maybe days-weeks on 8 CPU depend on parameters \n",
    "### Train $F^{ML}=\\epsilon \\beta n_i n_j +\\epsilon \\beta_2 n_i^{\\prime} n_j^{\\prime} n_k^{\\prime} $\n",
    "### in paper, train sq term  and cubic separate, then add together with noise then train \n",
    "### The idea is that cubic terms are more like correction terms \n",
    "### no guarantee this will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pymp\n",
    "num_thread = 8\n",
    "\n",
    "from numba import jit\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"fuzzy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['32', '0.03125', '256\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('LJ_data_'+file_dir+'/MC_parameter.dat', 'r')\n",
    "temp = f.read().split(\"\\t\")\n",
    "L=float(temp[0])\n",
    "dx=float(temp[1])\n",
    "N=int(L/dx)\n",
    "batch_size = int(temp[2])\n",
    "f.close()\n",
    "temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125\t1024\t32.0\t256\n"
     ]
    }
   ],
   "source": [
    "print(str(dx)+\"\\t\"+str(N)+\"\\t\"+str(L)+\"\\t\"+str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('LJ_data_'+file_dir+'/MC_inform.dat', 'r')\n",
    "MC_inform = f.read().splitlines()\n",
    "for i in range(len(MC_inform)):\n",
    "    #print(MC_inform[i])\n",
    "    MC_inform[i]=MC_inform[i].split(\"\\t\")\n",
    "f.close()\n",
    "batch_size = (len(MC_inform)//mini_batch)*mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125\t1024\t32.0\t256\n"
     ]
    }
   ],
   "source": [
    "print(str(dx)+\"\\t\"+str(N)+\"\\t\"+str(L)+\"\\t\"+str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_inform = np.array(MC_inform)\n",
    "MC_inform = MC_inform.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.03125, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nw = 8\n",
    "Lw = int(np.floor(8/dx)+1)\n",
    "LLw = int(np.floor(8/dx)/2)\n",
    "rho_array = np.zeros((mini_batch,N))\n",
    "rho0_array = np.zeros((mini_batch))\n",
    "epsilon_array = np.zeros((mini_batch))\n",
    "mu_array = np.zeros((mini_batch))\n",
    "Vext_array = np.zeros((mini_batch,N))\n",
    "Lw*dx,LLw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetry (epsilon):\n",
    "    for i in range(Nw):\n",
    "        for j in range(i,Nw):\n",
    "            for k in range(j,Nw):\n",
    "                temp = epsilon[i][j][k]\n",
    "                epsilon[i][k][j]=temp\n",
    "                epsilon[j][i][k]=temp\n",
    "                epsilon[j][k][i]=temp\n",
    "                epsilon[k][i][j]=temp\n",
    "                epsilon[k][j][i]=temp\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"initial w\"\"\"\n",
    "def initial_kernel():\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    w1 = np.random.normal(0,1,Nw*Lw)*0.01\n",
    "    w1=w1.reshape((Nw,Lw))\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    w2 = np.random.normal(0,1,Nw*Lw)*0.01\n",
    "    w2=w2.reshape((Nw,Lw))\n",
    "       \n",
    "    \n",
    "    np.random.seed(2)\n",
    "    beta1 = np.random.normal(0,1,Nw**2)*0.01\n",
    "    beta1=beta1.reshape((Nw,Nw))\n",
    "    beta1 = ((beta1)+beta1.T)/2\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    beta2 = np.random.normal(0,1,Nw**3)*0.01\n",
    "    beta2=  beta2.reshape((Nw,Nw,Nw))\n",
    "    beta2 = symmetry(beta2)\n",
    "    \n",
    "    return w1,w2,beta1,beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.010776632960948027 -0.010776632960948027\n",
      "-0.013138647533626821 -0.013138647533626821 -0.013138647533626821 -0.013138647533626821 -0.013138647533626821 -0.013138647533626821\n"
     ]
    }
   ],
   "source": [
    "w1,w2,beta1,beta2 = initial_kernel()\n",
    "print(beta1[0][2],beta1[2][0])\n",
    "print(beta2[0][2][1],beta2[2][1][0],beta2[1][2][0],beta2[1][0][2],beta2[2][0][1],beta2[2][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC_inform[32][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load data with shuffle\"\"\"\n",
    "def load_data (batch_number):\n",
    "    for j in range(mini_batch):\n",
    "        i = batch_number[j]\n",
    "        \n",
    "        rho_array[j]=np.loadtxt(\"LJ_data_\"+file_dir+\"/rho_\"+str(i)+\".dat\")\n",
    "        #rho_array[j]=(rho_array[j]+rho_array[j][::-1])/2 #force symmetry ? \n",
    "        \n",
    "        Vext_array[j]=np.loadtxt(\"LJ_data_\"+file_dir+\"/Vext_\"+str(i)+\".dat\")\n",
    "        epsilon_array[j]=float(MC_inform[i][1])\n",
    "        mu_array[j]=np.log(float(MC_inform[i][2]))\n",
    "        \n",
    "    return rho_array,Vext_array,epsilon_array,mu_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def conv (rho,w):\n",
    "\n",
    "    rho_pad=np.pad(rho,(LLw,LLw),'symmetric')\n",
    "    rho_pad[0:LLw]=rho_pad[N:N+LLw]\n",
    "    rho_pad[N+LLw:N+LLw*2]=rho_pad[LLw:LLw+LLw]\n",
    "    n = np.correlate(rho_pad,w)\n",
    "    \n",
    "    return n*dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def w_FMT(eps):\n",
    "    #d=cal_eff_diameter (eps)\n",
    "    R = 1.0/2\n",
    "    k=np.linspace(0,N//2,N//2+1)*2*np.pi/L\n",
    "    w0=2*np.cos(k*R)/2\n",
    "    k[0]=1 #keep notebook shutup\n",
    "    w1=2*np.sin(k*R)/k\n",
    "    w1[0]=2*R\n",
    "    return w0,w1;\n",
    "\n",
    "w0_FMT,w1_FMT = w_FMT(0)\n",
    "\n",
    "def cal_n0(rho):\n",
    "    return np.fft.irfft(np.fft.rfft(rho)*w0_FMT)\n",
    "def cal_n1(rho):\n",
    "    return np.fft.irfft(np.fft.rfft(rho)*w1_FMT)\n",
    "\n",
    "def cal_c1_FMT(rho,eps):\n",
    "    n0=cal_n0(rho)\n",
    "    n1=cal_n1(rho)\n",
    "    F0=-np.log(1-n1)\n",
    "    F1=n0/(1-n1)\n",
    "    return cal_n0(F0)+cal_n1(F1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"add FMT terms\"\"\"\n",
    "@jit\n",
    "def cal_c1(epsilon,beta1,beta2,n,nnw,w1,w2,rho):\n",
    "    c1 = np.zeros((N))\n",
    "       \n",
    "    for i in range(Nw):\n",
    "        for j in range(Nw):\n",
    "            c1+=epsilon*beta1[i][j]*(conv(n[i],w1[j])+conv(n[j],w1[i]))\n",
    "            \n",
    "    for i in range(Nw):\n",
    "        for j in range(Nw):\n",
    "            for k in range(Nw):\n",
    "                c1+=(epsilon*beta2[i][j][k])*(\n",
    "                    nnw[i][j][k]+nnw[i][k][j]+nnw[j][k][i])\n",
    "    c1+=cal_c1_FMT(rho,epsilon)\n",
    "    return c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def cal_mu_ML_test(epsilon,beta1,beta2,rho0,w1,w2):\n",
    "    c1=0\n",
    "    \n",
    "    for i in range(Nw):\n",
    "        for j in range(Nw):\n",
    "                ni = np.sum(rho0*w1[i])\n",
    "                nj = np.sum(rho0*w1[j])\n",
    "                c1+=(epsilon*beta1[i][j])*(\n",
    "                    np.sum(nj*w1[i])+np.sum(ni*w1[j]))*dx*dx\n",
    "    \n",
    "    \n",
    "    for i in range(Nw):\n",
    "        for j in range(Nw):\n",
    "            for k in range(Nw):\n",
    "                ni = np.sum(rho0*w2[i])\n",
    "                nj = np.sum(rho0*w2[j])\n",
    "                nk = np.sum(rho0*w2[k])\n",
    "                c1+=(epsilon*beta2[i][j][k])*(\n",
    "                    np.sum(ni*nj*w2[k])+np.sum(nj*nk*w2[i])+np.sum(nk*ni*w2[j]))*dx*dx*dx\n",
    "    rho_temp = np.full(N,rho0)\n",
    "    c1_FMT = cal_c1_FMT(rho_temp,epsilon)[0]\n",
    "    return c1+np.log(rho0)+c1_FMT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def f2 (c1,c2,x,mu,eps):\n",
    "    rho_temp = np.full(N,x)\n",
    "    c1_FMT = cal_c1_FMT(rho_temp,eps)[0]\n",
    "    return (c1*x+c2*x**2+np.log(x)+c1_FMT-mu)**2\n",
    "\n",
    "@jit\n",
    "def cal_rho0(mu,beta1,beta2,epsilon,w1,w2,mu_input):\n",
    "    \n",
    "    c1=0  \n",
    "    c2=0\n",
    "    \n",
    "    for i in range(Nw):\n",
    "        for j in range(Nw):\n",
    "            c1+=epsilon*beta1[i][j]*(\n",
    "                np.sum(np.sum(w1[i])*w1[j]))*dx**2*2\n",
    "    \n",
    "    \n",
    "    for i in range(Nw):\n",
    "        for j in range(Nw):\n",
    "            for k in range(Nw):\n",
    "                ni = np.sum(w2[i])\n",
    "                nj = np.sum(w2[j])\n",
    "                nk = np.sum(w2[k])\n",
    "                c2+=(epsilon*beta2[i][j][k])*(\n",
    "                    np.sum(ni*nj*w2[k])+np.sum(nj*nk*w2[i])+\n",
    "                    np.sum(nk*ni*w2[j]))*dx*dx*dx\n",
    "    \n",
    "    rho_guess = np.zeros(3)\n",
    "    res = np.zeros(3)\n",
    "    \n",
    "    interval = 0.01\n",
    "\n",
    "    for i in range(3):\n",
    "        rho_guess[i] = 0.3+interval*i\n",
    "        \n",
    "    for iteration in range (10000):\n",
    "        for i in range(3):\n",
    "            res[i] = f2(c1,c2,rho_guess[i],mu,epsilon)\n",
    "        if(res[0]>res[1] and res[2]>res[1]):\n",
    "            interval/=2\n",
    "            rho_guess[0]=rho_guess[1]-interval\n",
    "            rho_guess[2]=rho_guess[1]+interval\n",
    "        elif(res[1]>res[0] and res[2]>res[0]):\n",
    "            temp = rho_guess[0]\n",
    "            rho_guess[0]=temp-interval\n",
    "            rho_guess[1]=temp\n",
    "            rho_guess[2]=temp+interval\n",
    "        else:\n",
    "            temp = rho_guess[2]\n",
    "            rho_guess[0]=temp-interval\n",
    "            rho_guess[1]=temp\n",
    "            rho_guess[2]=temp+interval\n",
    "        if(interval<10**-8):\n",
    "            break        \n",
    "        for i in range (3):\n",
    "            if(rho_guess[i]<=0 or rho_guess[i]>=1):\n",
    "                break\n",
    "    temp=rho_guess[1]\n",
    "    #print(\"rho\\t=\\t\",temp,\"\\t z input=\",np.exp(mu_input), \"\\t z guess=\",np.exp(mu),\"\\t z predict=\",np.exp(cal_mu_ML_test(epsilon,beta1,beta2,temp,w1,w2)))\n",
    "    if(temp<0):\n",
    "        return 0.01\n",
    "    elif(temp>1):\n",
    "        return 0.9\n",
    "    else:\n",
    "        return rho_guess[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42057922363281264\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rho0=cal_rho0(np.log(1.5),beta1,beta2,0.5,w1,w2,np.log(1.5))\n",
    "\n",
    "print(rho0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def f (rho,c,rhoML):\n",
    "    return np.sum((rho-c*rhoML)**2)\n",
    "\n",
    "@jit\n",
    "def cal_mu_ML(rho,c1,Vext):\n",
    "    rhoML = np.exp(-c1-Vext)\n",
    "    mu_guess = np.zeros(3)\n",
    "    res = np.zeros(3)\n",
    "    \n",
    "    for i in range(3):\n",
    "        mu_guess[i] = i-1.0\n",
    "    interval = 1\n",
    "    \n",
    "    for iteration in range (1000):\n",
    "        for i in range(3):\n",
    "            res[i] = f(rho,mu_guess[i],rhoML)\n",
    "        if(res[0]>res[1] and res[2]>res[1]):\n",
    "            interval/=2\n",
    "            mu_guess[0]=mu_guess[1]-interval\n",
    "            mu_guess[2]=mu_guess[1]+interval\n",
    "        elif(res[1]>res[0] and res[2]>res[0]):\n",
    "            temp = mu_guess[0]\n",
    "            mu_guess[0]=temp-interval\n",
    "            mu_guess[1]=temp\n",
    "            mu_guess[2]=temp+interval\n",
    "        else:\n",
    "            temp = mu_guess[2]\n",
    "            mu_guess[0]=temp-interval\n",
    "            mu_guess[1]=temp\n",
    "            mu_guess[2]=temp+interval\n",
    "        if(interval<10**-8):\n",
    "            break\n",
    "    \n",
    "    return np.log(mu_guess[1])\n",
    "            \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def cal_rho_ML(mu,c1,V):\n",
    "    rho_ML = np.exp(-c1-V+mu)\n",
    "    return rho_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def error (rho,rho_ML):\n",
    "    return np.sum((rho-rho_ML)**2)*dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def Dbeta1_tot(rho_ML,rho,rho0,eps,n,w,i,j):\n",
    "    temp=np.zeros((N))    \n",
    "    for k in range(mini_batch):\n",
    "        c1=(np.sum(np.sum(rho0[k]*w[i])*w[j]))*2*dx**2  \n",
    "        temp+=(2.0)*(rho_ML[k]-rho[k])*rho_ML[k]*eps[k]*(c1-conv(n[k][i],w[j])-conv(n[k][j],w[i]))\n",
    "    \n",
    "    return np.sum(temp)*dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check epsilon\"\"\"\n",
    "@jit\n",
    "def Dbeta2_tot(rho_ML,rho,rho0,epsilon,nnw,w,i,j,k):\n",
    "    temp1=np.zeros((N))\n",
    "    temp2=np.zeros((N))\n",
    "    for MM in range(mini_batch):\n",
    "        ni = np.sum(rho0[MM]*w[i])\n",
    "        nj = np.sum(rho0[MM]*w[j])\n",
    "        nk = np.sum(rho0[MM]*w[k])\n",
    "        c1=(np.sum(ni*nj*w[k])+np.sum(nj*nk*w[i])+np.sum(nk*ni*w[j]))*dx*dx*dx\n",
    "        temp = (2.0)*(rho_ML[MM]-rho[MM])*rho_ML[MM]*(c1-nnw[MM][i][j][k]-nnw[MM][j][k][i]-nnw[MM][i][k][j])\n",
    "        temp1+=temp*epsilon[MM]\n",
    "        #temp2+=temp*epsilon[MM]**2\n",
    "    return np.sum(temp1)*dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def Dw1F(rhow,beta,j):\n",
    "    temp=np.zeros((N))\n",
    "    for i in range(Nw):\n",
    "        temp+=rhow[i]*beta[i][j]\n",
    "    return temp\n",
    "@jit\n",
    "def Dw1mu(beta,rho0,w,j):\n",
    "    c1=0\n",
    "    for i in range(Nw):\n",
    "        c1+=4*(beta[i][j])*(np.sum(rho0*w[i]))*dx**2\n",
    "    return c1\n",
    "\n",
    "@jit\n",
    "def Dw1_tot(rho_ML,rho,rho0,rhow,j,p,beta,eps,w):\n",
    "    temp=np.zeros(mini_batch)\n",
    "    for k in range(mini_batch): \n",
    "        temp[k]=np.sum((rho_ML[k]-rho[k])*(2)*rho_ML[k]*eps[k]*(\n",
    "            Dw1mu(beta,rho0[k],w,j)-Dw1F(rhow[k][p],beta,j)))\n",
    "    #print(temp)\n",
    "    return np.sum(temp)*dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def Dw2F(n,beta2,epsilon,k,p,w,rho,nij):\n",
    "    temp=np.zeros((N))\n",
    "    rho_new = np.roll(rho,-(p-LLw))\n",
    "    n_temp = np.zeros((Nw,N))\n",
    "    niconvj = np.zeros((Nw,Nw,N))     \n",
    "    \n",
    "    for i in range(Nw):\n",
    "        n_temp[i] = n[i]*rho_new\n",
    "    \n",
    "    for i in range(Nw):\n",
    "        for j in range(Nw):\n",
    "            niconvj[i][j] = conv(n_temp[i],w[j])\n",
    "     \n",
    "    \n",
    "    for i in range(Nw):\n",
    "        for j in range(Nw):\n",
    "            temp+=3*(epsilon*beta2[i][j][k])*np.roll(nij[i][j],-(p-LLw))*dx\n",
    "            temp+=3*(epsilon*beta2[i][j][k])*niconvj[i][j]*dx\n",
    "            temp+=3*(epsilon*beta2[i][j][k])*niconvj[j][i]*dx\n",
    "            \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def Dw2mu(beta2,epsilon,rho0,w,k):\n",
    "    c1=0\n",
    "        \n",
    "    for i in range(Nw):\n",
    "        ni=np.sum(rho0*w[i])\n",
    "        for j in range(Nw):\n",
    "            nj=np.sum(rho0*w[j])\n",
    "            c1+=9*(epsilon*beta2[i][j][k])*(ni*nj)*dx**3\n",
    "    return c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def Dw2_tot(rho_ML,rho,rho0,n,k,p,beta2,epsilon,w,nij):\n",
    "    temp=np.zeros(mini_batch)\n",
    "    for M in range(mini_batch): \n",
    "        temp[M]=np.sum((rho_ML[M]-rho[M])*(2)*rho_ML[M]*(Dw2mu(beta2,epsilon[M],rho0[M],w,k)-\n",
    "                                                         Dw2F(n[M],beta2,epsilon[M],\n",
    "                                                             k,p,w,rho[M],nij[M])))\n",
    "                                                                             \n",
    "    #print(temp)\n",
    "    return np.sum(temp)*dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def kernel_rhow(n_array,w):\n",
    "    rhow = np.zeros((Lw,Nw,N))\n",
    "    for k in range(Nw):\n",
    "        for p in range(Lw):\n",
    "            rhow[p][k]=np.roll(n_array[k],-(p-LLw))*dx*4\n",
    "    return rhow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ML_kernel(seed,w1,w2,beta1,beta2,alpha):\n",
    "    np.random.seed(seed)\n",
    "    batch_number=np.arange(batch_size)\n",
    "    np.random.shuffle(batch_number)\n",
    "    \n",
    "    dbeta1 = pymp.shared.array((beta1.shape))\n",
    "    dbeta2 = pymp.shared.array((beta2.shape))\n",
    "    dw1 = pymp.shared.array((w1.shape))\n",
    "    dw2 = pymp.shared.array((w2.shape))\n",
    "    \n",
    "    rhoML_array = pymp.shared.array((mini_batch,N))\n",
    "    n1_array = pymp.shared.array((mini_batch,Nw,N))\n",
    "    n2_array = pymp.shared.array((mini_batch,Nw,N))\n",
    "    \n",
    "    rhow = pymp.shared.array((mini_batch,Lw,Nw,N), dtype='float')\n",
    "\n",
    "    nnw = pymp.shared.array((mini_batch,Nw,Nw,Nw,N))\n",
    "    #nw = pymp.shared.array((mini_batch,Nw,Nw,N))\n",
    "    nij = pymp.shared.array((mini_batch,Nw,Nw,N))\n",
    "\n",
    "    epco_error = 0\n",
    "    N_minbatch = int(batch_size/mini_batch)\n",
    "    for M in range(N_minbatch):\n",
    "        print(str(M)+'/'+str(N_minbatch))\n",
    "        rho_array,Vext_array,epsilon_array,mu_array=load_data (batch_number[M*mini_batch:(M+1)*mini_batch])\n",
    "        \n",
    "        '''preparing n*w'''\n",
    "        \n",
    "        with pymp.Parallel(num_thread) as p:\n",
    "            for MM in p.range(mini_batch):\n",
    "                for j in range (Nw):\n",
    "                    n1_array[MM][j] = conv(rho_array[MM],w1[j])\n",
    "                    n2_array[MM][j] = conv(rho_array[MM],w2[j])\n",
    "                    \n",
    "\n",
    "        with pymp.Parallel(num_thread) as p:            \n",
    "            for MM in p.range(mini_batch):\n",
    "                for i in range(Nw):\n",
    "                    for j in range(Nw):\n",
    "                        nij[MM][i][j]=n2_array[MM][i]*n2_array[MM][j] \n",
    "        '''               \n",
    "        with pymp.Parallel(num_thread) as p:            \n",
    "            for MM in p.range(mini_batch):\n",
    "                for i in range(Nw):\n",
    "                    for j in range(Nw):\n",
    "                        nw[MM][i][j]=conv(n2_array[MM][i],w[j]) \n",
    "        '''            \n",
    "        with pymp.Parallel(num_thread) as p:            \n",
    "            for MM in p.range(mini_batch):\n",
    "                for i in range(Nw):\n",
    "                    for j in range(Nw):\n",
    "                        for k in range(Nw):\n",
    "                            nnw[MM][i][j][k]=conv(nij[MM][i][j],w2[k])\n",
    "                    \n",
    "        with pymp.Parallel(num_thread) as p:            \n",
    "            for MM in p.range(mini_batch):\n",
    "                c1 = cal_c1(epsilon_array[MM],beta1,beta2\n",
    "                            ,n1_array[MM],nnw[MM],w1,w2,rho_array[MM])\n",
    "                #print(c1.shape)\n",
    "                mu_ML = cal_mu_ML(rho_array[MM],c1,Vext_array[MM])\n",
    "                #print(\"z_input\",np.exp(mu_array[MM]))\n",
    "                rho0_array[MM]=cal_rho0(mu_ML,beta1,beta2,\n",
    "                                        epsilon_array[MM],w1,w2,mu_array[MM])\n",
    "                rhoML_array[MM] = cal_rho_ML(mu_ML,c1,Vext_array[MM])\n",
    "\n",
    "        epco_error+=error(rho_array,rhoML_array)\n",
    "        \n",
    "        with pymp.Parallel(num_thread) as p:\n",
    "            for i in p.range(Nw):\n",
    "                for j in range(i,Nw):\n",
    "                    dbeta1[i][j] =Dbeta1_tot(\n",
    "                        rhoML_array,rho_array,\n",
    "                        rho0_array,epsilon_array,n1_array,w1,\n",
    "                        i,j)\n",
    "                    dbeta1[j][i]=dbeta1[i][j]\n",
    "        \n",
    "        with pymp.Parallel(num_thread) as p:\n",
    "            for i in p.range(Nw):\n",
    "                for j in range(i,Nw):\n",
    "                    for k in range(j,Nw):\n",
    "                        dbeta2[i][j][k] =Dbeta2_tot(\n",
    "                            rhoML_array,rho_array,\n",
    "                            rho0_array,epsilon_array,nnw,w2,i,j,k)\n",
    "                        dbeta2[i][k][j]=dbeta2[i][j][k] \n",
    "                        dbeta2[j][i][k]=dbeta2[i][j][k] \n",
    "                        dbeta2[j][k][i]=dbeta2[i][j][k] \n",
    "                        dbeta2[k][i][j]=dbeta2[i][j][k] \n",
    "                        dbeta2[k][j][i]=dbeta2[i][j][k]             \n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        with pymp.Parallel(num_thread) as p:            \n",
    "            for MM in p.range(mini_batch):\n",
    "                rhow[MM]=kernel_rhow(n_array[MM],w)\n",
    "        \"\"\"\n",
    "        \n",
    "        #Dw2_tot(rho_ML,rho,rho0,n,k,p,beta2,epsilon,w,nij):\n",
    "        \n",
    "        with pymp.Parallel(num_thread) as p:            \n",
    "            for i in p.range(mini_batch):\n",
    "                rhow[i]=kernel_rhow(n1_array[i],w1)\n",
    "        \n",
    "        with pymp.Parallel(num_thread) as pp:            \n",
    "            for j in pp.range(Nw):\n",
    "                for p in range(Lw):\n",
    "                    dw1[j][p]=Dw1_tot(\n",
    "                        rhoML_array,rho_array,rho0_array,rhow,\n",
    "                        j,p,beta1,epsilon_array,w1)\n",
    "        \n",
    "        with pymp.Parallel(num_thread) as pp:            \n",
    "            for j in pp.range(Nw):\n",
    "                for p in range(Lw):\n",
    "                    dw2[j][p]=Dw2_tot(rhoML_array,rho_array,\n",
    "                                    rho0_array,n2_array,j,p,\n",
    "                                    beta2,epsilon_array,w2,nij)\n",
    "                    \n",
    "                    \n",
    "               \n",
    "        w1-=alpha*dw1*dx\n",
    "        beta1-=alpha*dbeta1*dx*dx\n",
    "        w2-=alpha*dw2\n",
    "        beta2-=alpha*dbeta2*dx\n",
    "        \n",
    "    return w1,w2,beta1,beta2,epco_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(w1,w2,beta1,beta2,error_array):\n",
    "    \"\"\"save kernel results\"\"\"\n",
    "    np.savetxt(r\"./ML_data/epco_error_sq_cubic.txt\",error_array)\n",
    "    np.savetxt(r\"./ML_data/w1_kernel_sq_cubic.txt\",w1)\n",
    "    np.savetxt(r\"./ML_data/w2_kernel_sq_cubic.txt\",w2)\n",
    "    np.savetxt(r\"./ML_data/beta1_kernel_sq_cubic.txt\",beta1)\n",
    "        \n",
    "    for i in range(Nw):\n",
    "        np.savetxt(r\"./ML_data/beta2_kernel_sq_cubic_\"+str(i)+\".txt\",beta2[i])\n",
    "        \n",
    "    f = open('./ML_data/parameter_kernel_sq_cubic.txt', 'w')\n",
    "    f.write(str(dx))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(Lw))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(Nw))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \"\"\"save done\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "0 10.840465462230163 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "1 9.996028286572757 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "2 9.163590230826754 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "3 8.33733137792191 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "4 7.5292215199767725 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "5 6.755954216531431 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "6 6.0335313645505355 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "7 5.376918242906097 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "8 4.800346791682026 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "9 4.310982054653844 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "10 3.9084183000545476 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "11 3.590182387657064 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "12 3.3455265908311196 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "13 3.163207958362577 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "14 3.030437521021674 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "15 2.9364502618620865 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "16 2.8697279405781972 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "17 2.8225791384740595 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "18 2.788882126024674 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "19 2.764072126012845 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "20 2.7456012224759743 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "21 2.7307095733966777 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "22 2.7188346461012145 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "23 2.7089170795806026 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "24 2.6985270518612348 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "25 2.689721640099326 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "26 2.6819004475005426 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "27 2.6737526155778695 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "28 2.6661450614055227 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "29 2.6582348233117443 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "30 2.6514633565255727 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "31 2.6445415230348086 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "32 2.637134925639322 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "33 2.630316167456382 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "34 2.623594776471758 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "35 2.617287043655886 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "36 2.610699096860767 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "37 2.60453579692685 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "38 2.597831607506357 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "39 2.592056689232417 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "40 2.585738084465977 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "41 2.580105545360232 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "42 2.574386061669365 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "43 2.568410805532864 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "44 2.5626821222623426 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "45 2.5572570067513656 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "46 2.551713881423204 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "47 2.5463301706268435 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "48 2.5412987718047266 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "49 2.5359982364606446 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "50 2.530784337787567 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "51 2.5253288139856953 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "52 2.520505345724251 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "53 2.5156881416732575 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "54 2.5112449188483437 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "55 2.506207981402515 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "56 2.5016375780716795 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "57 2.496761636035739 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "58 2.4928501471253166 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "59 2.487703379133598 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "60 2.4836359250447835 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "61 2.479250989071505 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "62 2.4749602000962616 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "63 2.470941421884641 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "64 2.4663633945372143 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "65 2.4621160882288438 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "66 2.458031354748755 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "67 2.454233028535594 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "68 2.4504184288481534 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "69 2.4463398432038224 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "70 2.4426077505643535 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "71 2.4388379575525043 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "72 2.4350906855157985 0.01\n",
      "0/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "73 2.4312291376485957 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "74 2.4280210337313504 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "75 2.424040195128082 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "76 2.4204822859598427 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "77 2.4167610651323614 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "78 2.4135143367839498 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "79 2.4093383607754446 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "80 2.4068498686151187 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "81 2.4027952734024742 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "82 2.3996359442471054 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "83 2.3967467200694688 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "84 2.3928638443285686 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "85 2.389801694621789 0.01\n",
      "0/16\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-116e23a8b11e>\u001b[0m in \u001b[0;36mML_kernel\u001b[0;34m(seed, w1, w2, beta1, beta2, alpha)\u001b[0m\n\u001b[1;32m    115\u001b[0m                                     \u001b[0mrho0_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                                     beta2,epsilon_array,w2,nij)\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;31m# If we get here, use new padding method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m     \u001b[0mnewmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ForkAwareLocal' object has no attribute 'connection'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f7dae89e5fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mbeta1_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mbeta2_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepco_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mML_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0merror_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepco_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0malpha_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-116e23a8b11e>\u001b[0m in \u001b[0;36mML_kernel\u001b[0;34m(seed, w1, w2, beta1, beta2, alpha)\u001b[0m\n\u001b[1;32m    114\u001b[0m                     dw2[j][p]=Dw2_tot(rhoML_array,rho_array,\n\u001b[1;32m    115\u001b[0m                                     \u001b[0mrho0_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                                     beta2,epsilon_array,w2,nij)\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymp/__init__.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_t, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc_t\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fork\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             _LOGGER.debug(\"Process %d done. Shutting down.\",\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    751\u001b[0m             util.debug('thread %r does not own a connection',\n\u001b[1;32m    752\u001b[0m                        threading.current_thread().name)\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'|'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accept_connection'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/managers.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(c, id, methodname, args, kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m     '''\n\u001b[1;32m     78\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#RETURN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "w1 = np.zeros(Nw*Lw)\n",
    "w2 = np.zeros(Nw*Lw)\n",
    "\n",
    "beta1 = np.zeros(Nw**2)\n",
    "beta2 = np.zeros(Nw**3)\n",
    "w1,w2,beta1,beta2=initial_kernel()\n",
    "\n",
    "error_array=np.empty(0)\n",
    "alpha_array=np.empty(0)\n",
    "start_time = timer()\n",
    "\n",
    "#loadfile####\n",
    "\n",
    "w1=np.loadtxt(\"./ML_data/w1_kernel_sq_cubic.txt\")\n",
    "temp=np.random.normal(0,1,w1.shape)*0.05\n",
    "w1+=temp\n",
    "\n",
    "w2=np.loadtxt(\"./ML_data/w_kernel_sq_cubic.txt\")\n",
    "temp=np.random.normal(0,1,w2.shape)*0.05\n",
    "w2+=temp\n",
    "\n",
    "beta1=np.loadtxt(\"./ML_data/beta1_kernel_sq_cubic.txt\")\n",
    "temp=np.random.normal(0,1,beta1.shape)*0.05\n",
    "beta1+=temp\n",
    "\n",
    "for i in range(Nw):\n",
    "    beta2[i]=np.loadtxt(\"./ML_data/beta2_sq_cubic\"+str(i)+\".txt\")\n",
    "temp=np.random.normal(0,1,beta2.shape)*0.05\n",
    "beta2+=temp\n",
    "    \n",
    "#print(w1.shape,w2.shape,beta1.shape,beta2.shape)\n",
    "#############\n",
    "save_data(w1,w2,beta1,beta2,error_array)\n",
    "alpha = 0.01\n",
    "for i in range(100000):\n",
    "    w1_old = np.copy(w1)\n",
    "    w2_old = np.copy(w2)\n",
    "    beta1_old = np.copy(beta1)\n",
    "    beta2_old = np.copy(beta2)\n",
    "    w1,w2,beta1,beta2,epco_error=ML_kernel(i,w1,w2,beta1,beta2,alpha)\n",
    "    error_array=np.append(error_array, epco_error)\n",
    "    alpha_array=np.append(alpha_array, alpha)\n",
    "    \n",
    "    if(alpha<10**-6 or np.isnan(epco_error)):\n",
    "        break\n",
    "        \n",
    "    if(epco_error>error_array[i-1] and i>0):\n",
    "        alpha/=2.0\n",
    "        print(\"alpha=\",alpha)\n",
    "    \n",
    "    print(i,epco_error,alpha)\n",
    "    save_data(w1,w2,beta1,beta2,error_array)\n",
    "end_time = timer()\n",
    "print(\"elapse=\"+'\\t'+str(end_time-start_time))\n",
    "save_data(w1,w2,beta1,beta2,error_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
